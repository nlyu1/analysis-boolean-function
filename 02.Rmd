# Influence and Spectral Learning

## Influence, Noise Stablity, and Social Choice {#Sec2}
This subsection corresponds to Chapter 2. Our focus is on 
the uniformity and dependence behavior of functions on their inputs. 

### Social choice functions {-}
A boolean function $\P^n\to \P$ may also be viewed 
as a voting function for an election with $2$ candidates 
and $n$ voters. The most common voting function, for odd $n$ 
is 
\[ 
    \maj_n(x) = \sgn\left(\sum x_j\right)
\] 

:::{.definition name="dictator, junta"}
The $i$-th dictator (projection) function is $\chi_i(x) = x_i$. 
Similarly, a function $\P^n\to \P$ is a $k$-junta if it depends 
upon _at most_ $k$ input coordinates. Informally, a function 
is a junta if it depends on a constant number of coordinates. 
:::

:::{.definition name="weighted majority (linear threshold) function"}
$f$ is a weighted majority function or, equivalently, a (linear) 
threshold function if, for some $a\in \R^n$ 
\[ 
    f(x) = \sgn(a\cdot x)
\] 
A depth-$d$ recursive majority of $n$ functions, denoted $\maj_n^{\otimes d}$ 
is a function of $n^d$ bits defined inductively 
\[ 
    \maj_n^{\otimes (d+1)}(x^{(1)}, \cdots, x^{(n)}) = 
    \maj_n(
        \maj_n^{\otimes d}(x^{(1)}), \cdots, \maj_n^{\otimes d}(x^{(n)})
    )
\] 
:::
:::{.definition name="tribes function"}
The tribes function of width $w$ and size $s$ $\Tribes_{ws}:\P^{ws}\to \P$ is 
\[ 
    \Tribes((x_{ws})) = \bigcup_{j=1}^s \left(\bigcap_{k=1}^w x_{ws}\right)
\] 
There are $s$ tribes, each containing $w$ elements. 
:::

### Dependence properties {-}
:::{.definition name="miscellaneous properties"} 
$f:\P^n\to \P$ (naturally extending to codomain $\R$) is

- monotone if $x\leq y\implies f(x)\leq f(y)$ where $x\leq y$ is defined coordinate-wise. 
- odd if $f(-x) = -f(x)$. 
- unanimous if $f(1, \cdots, 1)=1$ and $f(-1, \cdots, -1)=-1$. 
- symmetric if $f\circ \pi = f$ for all permutations. In other words, $f$ only depends 
    on the weight of $x$.
::: 
:::{.theorem name="May's theorem"} 
$f:\P^n \to \P$ is symmetric and monotone if and only if 
$f(x)=\sgn(1\cdot x+a_0)$. If $f$ is additionally odd, then $n$ must be odd 
and $f=\maj_n$. 
:::
_Proof:_ Symmetry demands $f(x)=g(1\cdot x)$ for some $g:\mbb N\to \R$. 
One may show that $y\mapsto \sgn(|y|+a_0)$ is the only admissible choice. 

Properties of functions we have seen so far: 

- Majority function for $n$ odd has all four properties. 
- The dictator function is monotone, odd, and unanimous, so do recursive majority functions. 
- Tribes functions are monotone, unanimous, and transitive-symmetric. 

:::{.definition name="transitive symmetry"}
$f$ is transitive-symmetric if for all $j, k\in [n]$ there exists 
a permutation $\pi\in S_n$ with $\pi(j)=k$ such that 
$f\circ \pi = f$. 

Symmetry demands that _all_ arrangements of coordinates are equivalent. 
Transitive symmetry only demands that every pair of 
coordinates are equivalent. 
:::

:::{.proposition #transitiveSymmetryLinearF} 
If $f$ is transitive symmetric, then 
\[ 
    \forall j, k: \hat f(j) = \hat f(k) 
\] 
:::
_Proof:_ If $f=f\circ \pi$, where $\pi$ is a permutation, 
then $\hat f = \hat f\circ \pi^{-1}$ since 
$\chi_J\circ \pi = \chi_{\pi^{-1}(J)}$. The result follows by 
definition of transitive symmetry. 

:::{.definition name="impartial culture assumption"}
The impartial culture assumption assumes that all $n$ voters' 
preferences are independent and uniformly random. This corresponds to 
voting in the absence of information. 
:::


### Influence, derivative, and expectation {-}
Given a coordinate $i\in [n]$ and binary string $x$, let $x^{\oplus i}$ denote 
the same string except with the $i$-th component flipped. 

:::{.definition #pivotInfluence name="pivot, influence"}
A coordinate $i\in [n]$ is pivotal for $f$ on input $x$ if 
$f(x)\neq f(x^{\oplus i})$. The influence of $i$ on $f$ is the probability 
that $i$ is pivotal for random input: 
\[  
    \Inf_i[f] = \Pr[f(\mbf x)\neq f(\mbf x^{\oplus i})]
\] 
:::
One may consider a boolean function providing a $2$-coloring 
of the hamming cube. Each boundary edge which connect vertices of different 
colorings then correspond a "change in decision." Consequently $\Inf_i$ 
is the fraction of boundary edges out of edges which involve a change in $x_i$. 

The dictator function satisfies $\Inf_j[\pm \chi_k]=\delta_{jk}$. The 
"or" and "and" functions satisfy $\Inf_i[\mrm{OR}_n] = \Inf_i[\mrm{AND}_n] = 2^{1-n}$. 

:::{.definition name="derivative"}
The $i$-th (discrete) derivative operator 
$\pd i:L^2(\P^n)\to L^2(\P^n)$ is defined by
\[ 
    \pd i f(x) = \df {f(x^{i\mapsto 1}) - f(x^{i\mapsto 0})} 2
\] 
Note that $\pd i f$ does not depend on $x_i$ anymore. 
It is also manifestly linear and obeys the product rule 
for the boolean function algebra. 
\[ 
    \pd i fg = (\pd i f)g + f(\pd i g)
\] 
Note that this is only true for $f, g\in L^2(\P^n)$, 
which are _multilinear_ polynomials in $(\chi_i)$. Then 
\[ 
    \pd i \chi_J = 
    \begin{cases} 
        \chi_{J-\{i\}} & i\in S \\ 
        0 & \text{otherwise}
    \end{cases} \implies 
    \pd i f = \sum_{i\in J} \hat f(J) \chi_{J - \{i\}}
\] 
We also have a fourier formula for influence 
\begin{equation}
    \Inf_i[f] = \Exp[(\pd i f(\mbf x))^2] = \|\pd i f\|_2^2 
    = \sum_{i\in J} \hat f(J)^2
    (\#eq:fourierInfluence)
\end{equation}
The influence of coordinate $i$ on $f$ is the sum of 
the fourier weights of $f$ on sets containing $i$. 
This constitutes the generalization of influence to real-valued boolean 
functions. 
:::
:::{.definition name="relevance"}
Coordinate $i$ is relevant for $f$ if $\Inf_i[f]>0$. 
In other words, there exists at least one $x$ for which 
$f(x)\neq f(x^{\oplus i})$. 
:::
:::{.proposition #monotoneInfluence name="influence of monotone functions"}
If $f$ is monotone, then $\Inf_i[f] = \hat f(i)$. 
:::
_Proof:_ By monoticity, $\pd i f(x) = 1$ (and never $-1$) 
if coordinate $i$ is pivotal for $x$. Then 
\[ 
    \Inf_i[f] = \Exp[\pd i f] = \la \pd i f, \chi_{\emptyset}] = 
    \widehat{\pd i f}(0) = \hat f(i)
\] 

:::{.proposition} 
If $f$ is transitive-symmetric and monotone, then 
\[ 
    \forall i: \inf_i[f] \leq 1/\sqrt n
\] 
:::
_Proof:_ the intuition here is that influence can only be positive, 
the total influence from all positions are bounded, and that any 
two positions are roughly equivalent. 
By proposition \@ref(prp:transitiveSymmetryLinearF) $\Inf_i[f] = \hat f(1)$ 
independent of $i$. By Parseval 
\[ 
    \Exp[f^2] = 1 = \sum \hat f(J)^2 \geq \sum_j \hat f(j)^2 = n\hat f(1)^2 
    \implies \Inf_i[f] = \hat f(1) \leq 1/\sqrt n
\] 

:::{.definition name="expectation operator, Laplacian"}
The $i$-th expectation operator is the linear operator 
\[ 
    \Exp_i f(x) = \Exp_{\mbf x_i}[f(x_1, \cdots, \mbf x_i, \cdots, x_n)]
\] 
Note that $\Exp_i f$ again does not depend on $x_i$. For boolean functions, 
following the analysis for $\pd j$ above 
\begin{align}
    \Exp_i f(x) &= \df{f(x^{i\to 1}) + f(x^{(i\to -1)})} 2 \\ 
    f(x) &= x_j \pd j f(x) + \Exp_j f(x) \quad \text{for any fixed $j$} \\ 
    \Exp_i f &= \sum_{i\notin J} \hat f(J) \chi_J 
\end{align}
The coordinate Laplacian operator $\Lap_i$ is defined by 
\[ 
    \Lap_i f = f - \Exp_i f = x_i \pd i f
\] 
It follows immediately from fourier formulas and previous definitions that 
\begin{align}
    \Lap_i f(x) &= x_i \pd i f(x) 
    = \df{f(x) - f(x^{\oplus i})} 2 = \sum_{i\in J}\hat f(J) \chi_J\\ 
   \Inf_i[f] &= \sum_{i\in J} \hat f(J)^2 = \la \Lap_i f, \Lap_i f\ra = \la f, \Lap_i f\ra 
\end{align}
:::

### Total influence {-}
:::{.definition name="total influence, sensitivity"}
The total influence of $f:\P^n\to \R$ is 
\[ 
    \Inft[f] = \sum \Inf_j[f]
\] 
The sensitivity is defined as 
\[ 
    \sens_f(x) = \text{number of pivotal coordinates of $f$ at $x$}
\] 
For boolean functions, the total influence equal to 
the average sensitivity
\[ 
    \Inft[f] = \sum_j \Pr[f(\mbf x)\neq f(\mbf x^{\oplus j}) 
    = \Exp\left[\sum_j 1_{f(\mbf x)\neq f(\mbf x^{\oplus j})}\right] 
    = \Exp[\sens_f(\mbf x)]
\] 
Proposition \@ref(prp:monotoneInfluence) implies that for monotone 
functions, $\Inft[f] = \sum \hat f(j)$. 
:::
:::{.proposition}
The fraction of boundary edges in the Hamming cube is $\Inft[f]/n$. 
:::
_Proof:_ Follows immediately from our discussion \@ref(def:pivotInfluence) 
that $\Inf_i[f]$ is the fraction of boundary edges for 
$i$-component changing edges in the $f$-coloring of the Hamming cube. 

The linear fourier coefficients have a natural interpretation from a 
social choice perspective. 

:::{.proposition}
Let $f:\P^n\to \P$ be a voting rule for a $2$-candidate election. 
Given votes $\mbf x$ and let $\mbf w$ be the number of votes which agree with the 
outcome $f(\mbf x)$ of the election, then 
\[ 
    \Exp[\mbf w] = \df n 2 + \df 1 2 \sum \hat f(j) 
\] 
:::
_Proof:_ Follows immediately from the definition of $\mbf w$ and 
\[ 
    \sum \hat f(j) = \Exp[f(\mbf x)(\mbf x_1 + \cdots + \mbf x_n)]
\] 